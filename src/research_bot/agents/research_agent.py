"""
Research agent that autonomously gathers and synthesizes information.

LEARNING NOTE: This file demonstrates advanced concepts:
1. Agentic loops - AI making decisions autonomously
2. Tool use - Claude deciding which tools to call and when
3. Dataclasses with field() - complex default values
4. API integration - calling Claude's API
5. Message passing - maintaining conversation state

The agent operates in a loop: search → fetch → analyze → decide if done.
Claude controls the research process using available tools.
"""

import json  # For converting data to/from JSON format
from dataclasses import dataclass, field  # field() for complex defaults
from typing import Any

import anthropic  # Official Anthropic SDK for calling Claude

from ..config import Config
from ..tools.base import BaseTool
from ..tools.web_search import WebSearchTool
from ..tools.content_fetcher import ContentFetcherTool
from ..extractors import DataExtractor, ExtractedData


# LEARNING NOTE - Dictionary as a lookup table:
# This dictionary stores pricing for different Claude models
# Key: model name, Value: dict with "input" and "output" prices per million tokens
# Pricing per million tokens (as of 2024)
MODEL_PRICING = {
    "claude-sonnet-4-20250514": {"input": 3.00, "output": 15.00},
    "claude-opus-4-20250514": {"input": 15.00, "output": 75.00},
    "claude-haiku-3-5-20241022": {"input": 0.80, "output": 4.00},
    "default": {"input": 3.00, "output": 15.00},  # Fallback if model not found
}


@dataclass
class TokenUsage:
    """
    Tracks token usage and calculates cost.

    LEARNING NOTE - What are tokens?
    Tokens are pieces of text. Roughly 1 token = 4 characters or 0.75 words.
    "Hello world" ≈ 2-3 tokens.

    Claude charges for:
    - Input tokens: text you send TO Claude
    - Output tokens: text Claude generates
    """

    input_tokens: int = 0  # Tokens sent to Claude
    output_tokens: int = 0  # Tokens generated by Claude
    model: str = ""  # Which model was used

    @property
    def total_tokens(self) -> int:
        """Calculate total tokens used (input + output)."""
        return self.input_tokens + self.output_tokens

    @property
    def cost_usd(self) -> float:
        """
        Calculate the cost in USD for this token usage.

        LEARNING NOTE - Dictionary .get() method:
        pricing = MODEL_PRICING.get(key, default)
        If key exists, return MODEL_PRICING[key]
        If key doesn't exist, return default value
        This prevents KeyError if model name isn't in dictionary.

        LEARNING NOTE - Underscores in numbers:
        1_000_000 is the same as 1000000
        Python ignores underscores in numbers - they're just for readability!
        """
        # Get pricing for this model, or use default if not found
        pricing = MODEL_PRICING.get(self.model, MODEL_PRICING["default"])

        # Calculate cost: (tokens / 1 million) * price per million
        input_cost = (self.input_tokens / 1_000_000) * pricing["input"]
        output_cost = (self.output_tokens / 1_000_000) * pricing["output"]

        return input_cost + output_cost

    def add(self, input_tokens: int, output_tokens: int):
        """Add tokens from a new API call to the running total."""
        self.input_tokens += input_tokens
        self.output_tokens += output_tokens


@dataclass
class ResearchResult:
    """
    Output from a completed research task.

    LEARNING NOTE - Why use field(default_factory=list)?
    If you write: sources: list = []
    ALL instances share the SAME list! This causes bugs.

    Instead use: sources: list = field(default_factory=list)
    This creates a NEW empty list for EACH instance.

    Think of it like:
    - Wrong: "Everyone shares one shopping cart"
    - Right: "Everyone gets their own shopping cart"
    """

    query: str  # The research question
    summary: str  # Final answer/summary of findings

    # LEARNING NOTE - list[dict[str, str]] means:
    # "A list where each item is a dictionary with string keys and string values"
    # Example: [{"url": "...", "title": "..."}, {"url": "...", "title": "..."}]
    sources: list[dict[str, str]] = field(default_factory=list)

    raw_findings: list[str] = field(default_factory=list)  # Raw text from sources
    iterations: int = 0  # How many research loops were performed
    usage: TokenUsage = field(default_factory=TokenUsage)  # Token usage tracking
    completed: bool = True  # False if hit max iterations before finishing

    # === NEW: Structured output fields ===
    # LEARNING NOTE - Structured Output:
    # These fields organize research into actionable sections.
    # They're populated from the summary WITHOUT extra API calls.

    # Key findings as bullet points
    # Example: ["AI market growing 40% YoY", "GPT-4 leads in benchmarks"]
    key_findings: list[str] = field(default_factory=list)

    # Extracted data (stats, dates, specs, code, etc.)
    # This is populated by DataExtractor - no API calls!
    extracted_data: ExtractedData = field(default_factory=ExtractedData)

    # Research metadata
    # Example: {"topic": "AI", "focus": "market trends", "depth": "comprehensive"}
    metadata: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        """
        Convert result to a dictionary for JSON export.

        LEARNING NOTE - Serialization:
        This converts our dataclass to a plain dict that can be
        easily converted to JSON, saved to file, or sent over network.
        """
        return {
            "query": self.query,
            "summary": self.summary,
            "sources": self.sources,
            "key_findings": self.key_findings,
            "extracted_data": self.extracted_data.to_dict(),
            "metadata": self.metadata,
            "iterations": self.iterations,
            "completed": self.completed,
            "usage": {
                "input_tokens": self.usage.input_tokens,
                "output_tokens": self.usage.output_tokens,
                "total_tokens": self.usage.total_tokens,
                "cost_usd": self.usage.cost_usd,
                "model": self.usage.model,
            },
        }


# LEARNING NOTE - XML-style tags:
# These are markers Claude uses to indicate when research is complete
# We search for these in Claude's responses to know when to stop
COMPLETION_TAG = "<research_complete>"
COMPLETION_END_TAG = "</research_complete>"

# LEARNING NOTE - System Prompt:
# This is like giving Claude instructions for its "job".
# The system prompt defines Claude's role, behavior, and how to respond.
# It's sent with every API call to set context.

# More efficient system prompt - encourages faster completion
SYSTEM_PROMPT = """You are a fast, efficient research agent. Your goal is to quickly find accurate information and provide a comprehensive answer.

IMPORTANT: Be efficient with API calls. Don't over-research.
- 1-2 searches are usually enough for simple topics
- Only fetch content from the most relevant 2-3 sources
- Stop as soon as you have enough information to answer well

Research strategy:
1. Start with one focused web search
2. Fetch content from the 1-3 most relevant results
3. If you have enough info, provide your answer immediately
4. Only do additional searches if the first results were insufficient

Available tools:
- web_search: Search the web (use focused, specific queries)
- fetch_content: Read a URL's content (only fetch what you need)

When ready (aim for 2-4 iterations), wrap your answer in:
<research_complete>
Your answer here with citations.
</research_complete>

Be concise but thorough. Cite sources with URLs."""

# Prompt used when forcing a summary after max iterations
SUMMARIZE_PROMPT = """Based on the research conducted so far, provide a comprehensive summary of what was found.

Even if the research feels incomplete, synthesize the available information into a useful answer. Include:
1. Key findings from the sources reviewed
2. Direct answers to the original query where possible
3. Citations to sources used
4. Any important caveats about what wasn't fully researched

Wrap your response in:
<research_complete>
Your summary here
</research_complete>"""


class ResearchAgent:
    """
    Autonomous research agent powered by Claude.

    LEARNING NOTE - What is an Agentic Loop?
    An agentic loop is when AI makes decisions autonomously in a cycle:
    1. AI decides what to do next (e.g., "I need to search for X")
    2. AI calls a tool (e.g., web_search)
    3. AI receives results
    4. AI analyzes and decides: continue or finish?
    5. Repeat until done

    This is different from a simple chatbot - the AI is in control,
    deciding what actions to take to achieve a goal.

    Runs an agentic loop where Claude decides which tools to use,
    what to search for, and when research is complete.
    """

    def __init__(self, config: Config | None = None, tools: list[BaseTool] | None = None):
        """
        Initialize the research agent.

        LEARNING NOTE - Default parameters with None:
        config: Config | None = None means:
        - Parameter can be Config OR None
        - If not provided, defaults to None
        - We then use "or" to provide a fallback

        LEARNING NOTE - The "or" operator trick:
        x = config or Config.from_env()
        If config is provided, use it. If None (falsy), use Config.from_env()
        """
        # Use provided config or load from environment
        self.config = config or Config.from_env()
        self.config.validate()  # Make sure config is valid

        # Create Claude API client
        self.client = anthropic.Anthropic(api_key=self.config.anthropic_api_key)

        # Set up tools (or use defaults)
        self.tools = tools or [
            WebSearchTool(max_results=self.config.max_search_results),
            ContentFetcherTool(timeout=self.config.timeout_seconds),
        ]

        # LEARNING NOTE - Dictionary comprehension:
        # {key: value for item in list} creates a dict from a list
        # This creates: {"web_search": WebSearchTool, "fetch_content": ContentFetcherTool}
        # Allows quick lookup: self.tool_map["web_search"] to get the tool
        self.tool_map = {tool.name: tool for tool in self.tools}

        # Data extractor for structured output (no API calls!)
        self.data_extractor = DataExtractor()

    async def research(self, query: str) -> ResearchResult:
        """
        Research a topic autonomously.

        LEARNING NOTE - This is the AGENTIC LOOP!
        This method is the core of the entire bot. Here's how it works:

        1. We maintain a "messages" list - this is the conversation with Claude
        2. Each iteration, we send messages to Claude
        3. Claude responds with either:
           - Text (thinking/analysis)
           - Tool use requests (I want to search for X)
           - Completion signal (research_complete tag)
        4. If Claude requests tools, we execute them and add results to messages
        5. Send the updated messages back to Claude
        6. Repeat until Claude signals completion or max iterations reached

        Always returns a useful result, even if max iterations reached.
        """
        # LEARNING NOTE - Message format:
        # Messages is a list of dictionaries: [{"role": "user", "content": "..."}]
        # Roles can be "user" (human) or "assistant" (Claude)
        # This maintains the conversation history
        messages = [{"role": "user", "content": f"Research this topic efficiently: {query}"}]

        # Track what we've found during research
        sources: list[dict[str, str]] = []  # URLs and titles we fetched
        raw_findings: list[str] = []  # Raw text content from those URLs
        usage = TokenUsage(model=self.config.model)  # Track API usage

        # LEARNING NOTE - The agentic loop:
        # range(1, max_iterations + 1) creates: 1, 2, 3, ..., max_iterations
        # We iterate a maximum number of times to prevent infinite loops
        for iteration in range(1, self.config.max_iterations + 1):
            # LEARNING NOTE - API call to Claude:
            # This sends our messages to Claude and gets a response
            # We provide:
            # - model: which Claude version to use
            # - max_tokens: maximum length of response
            # - system: instructions for how Claude should behave
            # - tools: list of tools Claude can call
            # - messages: the conversation history so far
            response = self.client.messages.create(
                model=self.config.model,
                max_tokens=self.config.max_tokens,
                system=SYSTEM_PROMPT,  # Tells Claude it's a research agent
                # Convert our tools to Claude's expected format
                tools=[t.to_claude_tool() for t in self.tools],
                messages=messages,  # Send conversation history
            )

            # Track token usage for cost calculation
            usage.add(response.usage.input_tokens, response.usage.output_tokens)

            # LEARNING NOTE - Processing Claude's response:
            # Claude can return multiple "content blocks" in one response:
            # - Text blocks: Claude's thoughts/analysis
            # - Tool use blocks: Claude wants to call a tool
            # We need to process all blocks and handle each type

            assistant_content = []  # What Claude said/did (for conversation history)
            tool_results = []  # Results from executing tools (to send back to Claude)

            # Loop through each content block in Claude's response
            for block in response.content:
                if block.type == "text":
                    # LEARNING NOTE - Text block:
                    # Claude is "thinking out loud" or providing analysis
                    # Save it to conversation history
                    assistant_content.append({"type": "text", "text": block.text})

                    # Check if Claude signaled completion
                    # LEARNING NOTE - String search:
                    # "in" operator checks if substring exists: "cat" in "concatenate" → True
                    if COMPLETION_TAG in block.text:
                        # Research is done! Extract the summary and return
                        summary = self._extract_summary(block.text)
                        result = ResearchResult(
                            query=query,
                            summary=summary,
                            sources=sources,
                            raw_findings=raw_findings,
                            iterations=iteration,
                            usage=usage,
                            completed=True,
                        )
                        # Enrich with structured data (no extra API calls!)
                        return self._enrich_result(result)

                elif block.type == "tool_use":
                    # LEARNING NOTE - Tool use block:
                    # Claude decided to call a tool! For example:
                    # {
                    #   "type": "tool_use",
                    #   "name": "web_search",
                    #   "input": {"query": "Python tutorials"}
                    # }
                    # We need to execute the tool and return results

                    # Save tool use to conversation history
                    assistant_content.append({
                        "type": "tool_use",
                        "id": block.id,  # Unique ID for this tool call
                        "name": block.name,  # Which tool: "web_search" or "fetch_content"
                        "input": block.input,  # Parameters Claude provided
                    })

                    # Execute the tool and get results
                    result = await self._execute_tool(block.name, block.input)

                    # Prepare tool results to send back to Claude
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": block.id,  # Match with the request ID
                        "content": json.dumps(result),  # Convert to JSON string
                    })

                    # If we fetched content, track it as a source
                    if block.name == "fetch_content" and "content" in result:
                        sources.append({
                            "url": block.input.get("url", ""),
                            "title": result.get("title", ""),
                        })
                        # Save first 2000 chars of content for later
                        raw_findings.append(result.get("content", "")[:2000])

            # LEARNING NOTE - Building conversation history:
            # We add Claude's response to messages so it "remembers" what it said
            # Format: {"role": "assistant", "content": [text and tool use blocks]}
            messages.append({"role": "assistant", "content": assistant_content})

            # If Claude called tools, add the results as a "user" message
            # This is how Claude receives the tool results to analyze
            if tool_results:
                messages.append({"role": "user", "content": tool_results})

            # LEARNING NOTE - Early exit condition:
            # If Claude stopped naturally (end_turn) without calling tools
            # or signaling completion, it probably finished in a different way
            # Use its last message as the summary
            if response.stop_reason == "end_turn" and not tool_results:
                last_text = self._get_last_text(response.content)
                result = ResearchResult(
                    query=query,
                    summary=last_text,
                    sources=sources,
                    raw_findings=raw_findings,
                    iterations=iteration,
                    usage=usage,
                    completed=True,
                )
                # Enrich with structured data (no extra API calls!)
                return self._enrich_result(result)

            # LEARNING NOTE - The loop continues:
            # If we reach here, Claude hasn't finished yet
            # The loop continues with updated messages
            # Next iteration, Claude will see tool results and decide what to do next

        # LEARNING NOTE - Max iterations reached:
        # If we exit the loop, we've hit max iterations without Claude finishing
        # Force Claude to summarize what we found so far
        return await self._force_summary(
            query, messages, sources, raw_findings, usage
        )

    async def _force_summary(
        self,
        query: str,
        messages: list,
        sources: list[dict[str, str]],
        raw_findings: list[str],
        usage: TokenUsage,
    ) -> ResearchResult:
        """Force Claude to summarize findings when max iterations reached."""

        # Add a message asking for summary
        messages.append({
            "role": "user",
            "content": SUMMARIZE_PROMPT,
        })

        response = self.client.messages.create(
            model=self.config.model,
            max_tokens=self.config.max_tokens,
            system=SYSTEM_PROMPT,
            messages=messages,
        )

        usage.add(response.usage.input_tokens, response.usage.output_tokens)

        # Extract the summary
        summary = ""
        for block in response.content:
            if block.type == "text":
                if COMPLETION_TAG in block.text:
                    summary = self._extract_summary(block.text)
                else:
                    summary = block.text
                break

        # If still no summary, create one from raw findings
        if not summary and raw_findings:
            summary = self._create_fallback_summary(query, sources, raw_findings)
        elif not summary:
            summary = f"Research on '{query}' was attempted but no results were gathered. Try a more specific query or increase max iterations."

        result = ResearchResult(
            query=query,
            summary=summary,
            sources=sources,
            raw_findings=raw_findings,
            iterations=self.config.max_iterations,
            usage=usage,
            completed=False,  # Mark as incomplete so user knows
        )
        # Enrich with structured data (no extra API calls!)
        return self._enrich_result(result)

    def _create_fallback_summary(
        self,
        query: str,
        sources: list[dict[str, str]],
        raw_findings: list[str],
    ) -> str:
        """Create a basic summary from raw findings if Claude fails to summarize."""
        summary = f"Research Summary: {query}\n\n"
        summary += "Note: Maximum iterations reached. Here's what was found:\n\n"

        for i, (source, finding) in enumerate(zip(sources, raw_findings), 1):
            title = source.get("title", "Untitled")
            url = source.get("url", "")
            # Truncate finding for readability
            excerpt = finding[:500] + "..." if len(finding) > 500 else finding
            summary += f"From {title}:\n{excerpt}\n\nSource: {url}\n\n"

        return summary

    async def _execute_tool(self, name: str, inputs: dict) -> dict:
        tool = self.tool_map.get(name)
        if tool:
            return await tool.execute(**inputs)
        return {"error": f"Unknown tool: {name}"}

    def _extract_summary(self, text: str) -> str:
        start = text.find(COMPLETION_TAG) + len(COMPLETION_TAG)
        end = text.find(COMPLETION_END_TAG)
        if end > start:
            return text[start:end].strip()
        return text[start:].strip()

    def _get_last_text(self, content: list) -> str:
        for block in reversed(content):
            if hasattr(block, "type") and block.type == "text":
                return block.text
        return ""

    def research_sync(self, query: str) -> ResearchResult:
        import asyncio
        return asyncio.run(self.research(query))

    def _enrich_result(self, result: ResearchResult) -> ResearchResult:
        """
        Enrich research result with structured data.

        LEARNING NOTE - Post-processing without API calls:
        This method extracts structured data from the existing summary
        and raw findings. It uses regex/pattern matching - NO extra API calls!
        This keeps costs at $0 for the enrichment step.
        """
        # Combine all text for extraction
        all_text = result.summary
        if result.raw_findings:
            all_text += "\n\n" + "\n\n".join(result.raw_findings)

        # Extract structured data (specs, stats, dates, code, etc.)
        result.extracted_data = self.data_extractor.extract_all(all_text)

        # Extract key findings from summary
        result.key_findings = self._extract_key_findings(result.summary)

        # Add metadata
        result.metadata = {
            "query": result.query,
            "model": result.usage.model,
            "sources_count": len(result.sources),
            "has_code": len(result.extracted_data.code_snippets) > 0,
            "has_specs": len(result.extracted_data.specifications) > 0,
            "has_pricing": len(result.extracted_data.prices) > 0,
        }

        return result

    def _extract_key_findings(self, summary: str) -> list[str]:
        """
        Extract key findings from the summary text.

        LEARNING NOTE - Pattern matching for bullet points:
        We look for common patterns that indicate key points:
        - Lines starting with "- " or "* "
        - Numbered lists (1. 2. 3.)
        - Lines starting with "Key:" or containing "important"

        This is heuristic-based - no API calls needed!
        """
        import re
        findings = []

        # Split into lines
        lines = summary.split('\n')

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Match bullet points: "- item" or "* item"
            if re.match(r'^[-*•]\s+(.+)', line):
                finding = re.sub(r'^[-*•]\s+', '', line)
                if len(finding) > 10:  # Skip very short items
                    findings.append(finding)

            # Match numbered lists: "1. item" or "1) item"
            elif re.match(r'^\d+[.)]\s+(.+)', line):
                finding = re.sub(r'^\d+[.)]\s+', '', line)
                if len(finding) > 10:
                    findings.append(finding)

        # Limit to top 10 findings
        return findings[:10]
